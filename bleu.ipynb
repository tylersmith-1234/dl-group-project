{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tyler/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/usr/local/anaconda3/envs/cs-7643/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate import bleu\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
    "from modelT5 import T5Model\n",
    "import os\n",
    "import argparse\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 22:32:32.188191: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-27 22:32:32.203597: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at data/t5savedv4.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/COMBINED/test.tsv', sep = '\\t', names=['in', 'expected'])\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained('data/t5savedv4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 13.94ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "def preprocess_function(examples):\n",
    "    prefix = 'paraphrase: '\n",
    "    inputs = [prefix + doc for doc in examples[\"in\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"expected\"], max_length=512, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors=\"tf\")\n",
    "tokenized_test = dataset_test.map(preprocess_function, batched=True)\n",
    "tokenized_test_small = tokenized_test.shuffle(seed=42).select(range(1500))\n",
    "tf_test_set = tokenized_test_small.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "      <th>expected</th>\n",
       "      <th>sentence_inputs</th>\n",
       "      <th>to_model</th>\n",
       "      <th>encoding</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCCW's chief operating officer, Mike Butcher, ...</td>\n",
       "      <td>Current Chief Operating Officer Mike Butcher a...</td>\n",
       "      <td>[PCCW's, chief, operating, officer,, Mike, But...</td>\n",
       "      <td>paraphrase: PCCW's chief operating officer, Mi...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(2104, shape=(), dtype=int32), tf.T...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The world's two largest automakers said their ...</td>\n",
       "      <td>Domestic sales at both GM and No. 2 Ford Motor...</td>\n",
       "      <td>[The, world's, two, largest, automakers, said,...</td>\n",
       "      <td>paraphrase: The world's two largest automakers...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(37, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the federal Centers for Disease C...</td>\n",
       "      <td>The Centers for Disease Control and Prevention...</td>\n",
       "      <td>[According, to, the, federal, Centers, for, Di...</td>\n",
       "      <td>paraphrase: According to the federal Centers f...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(2150, shape=(), dtype=int32), tf.T...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
       "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
       "      <td>[A, tropical, storm, rapidly, developed, in, t...</td>\n",
       "      <td>paraphrase: A tropical storm rapidly developed...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(71, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The company didn't detail the costs of the rep...</td>\n",
       "      <td>But company officials expect the costs of the ...</td>\n",
       "      <td>[The, company, didn't, detail, the, costs, of,...</td>\n",
       "      <td>paraphrase: The company didn't detail the cost...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(37, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  in  \\\n",
       "0  PCCW's chief operating officer, Mike Butcher, ...   \n",
       "1  The world's two largest automakers said their ...   \n",
       "2  According to the federal Centers for Disease C...   \n",
       "3  A tropical storm rapidly developed in the Gulf...   \n",
       "4  The company didn't detail the costs of the rep...   \n",
       "\n",
       "                                            expected  \\\n",
       "0  Current Chief Operating Officer Mike Butcher a...   \n",
       "1  Domestic sales at both GM and No. 2 Ford Motor...   \n",
       "2  The Centers for Disease Control and Prevention...   \n",
       "3  A tropical storm rapidly developed in the Gulf...   \n",
       "4  But company officials expect the costs of the ...   \n",
       "\n",
       "                                     sentence_inputs  \\\n",
       "0  [PCCW's, chief, operating, officer,, Mike, But...   \n",
       "1  [The, world's, two, largest, automakers, said,...   \n",
       "2  [According, to, the, federal, Centers, for, Di...   \n",
       "3  [A, tropical, storm, rapidly, developed, in, t...   \n",
       "4  [The, company, didn't, detail, the, costs, of,...   \n",
       "\n",
       "                                            to_model  \\\n",
       "0  paraphrase: PCCW's chief operating officer, Mi...   \n",
       "1  paraphrase: The world's two largest automakers...   \n",
       "2  paraphrase: According to the federal Centers f...   \n",
       "3  paraphrase: A tropical storm rapidly developed...   \n",
       "4  paraphrase: The company didn't detail the cost...   \n",
       "\n",
       "                      encoding  \\\n",
       "0  [input_ids, attention_mask]   \n",
       "1  [input_ids, attention_mask]   \n",
       "2  [input_ids, attention_mask]   \n",
       "3  [input_ids, attention_mask]   \n",
       "4  [input_ids, attention_mask]   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  ((tf.Tensor(2104, shape=(), dtype=int32), tf.T...   \n",
       "1  ((tf.Tensor(37, shape=(), dtype=int32), tf.Ten...   \n",
       "2  ((tf.Tensor(2150, shape=(), dtype=int32), tf.T...   \n",
       "3  ((tf.Tensor(71, shape=(), dtype=int32), tf.Ten...   \n",
       "4  ((tf.Tensor(37, shape=(), dtype=int32), tf.Ten...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...  \n",
       "1  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...  \n",
       "2  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...  \n",
       "3  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...  \n",
       "4  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sentence_inputs'] = df_test.apply(lambda x: x['in'].split(), axis=1)\n",
    "df_test['to_model'] = df_test.apply(lambda x: 'paraphrase: ' + x['in'], axis=1)\n",
    "df_test['encoding'] = df_test.apply(lambda x: tokenizer(x['in'], return_tensors=\"tf\", truncation=True), axis=1)\n",
    "df_test['input_ids'] = df_test.apply(lambda x: x['encoding']['input_ids'], axis=1)\n",
    "df_test['attention_mask'] = df_test.apply(lambda x: x['encoding']['attention_mask'], axis=1)\n",
    "# def model_func(x):\n",
    "#     return model.generate(\n",
    "#         input_ids=x['encoding']['input_ids'],\n",
    "#         do_sample=True,\n",
    "#         attention_mask=x['encoding']['attention_mask'],\n",
    "#         max_length=512, top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=2)\n",
    "# df_test['out'] = df_test.apply(lambda x: model_func(x), axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 61])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_used = 500\n",
    "preds_returned = 2\n",
    "full_outs = []\n",
    "inps = tokenizer(df_test['in'].values.tolist()[:500],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 73])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[500:1000],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1000, 86]), 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[1000:1500],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape, len(full_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1000, 115]), 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[1500:2000],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape, len(full_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1000, 68]), 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[2000:2500],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape, len(full_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1000, 76]), 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[2500:3000],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape, len(full_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1000, 74]), 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[3000:3500],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape, len(full_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1000, 69]), 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[3500:4000],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape, len(full_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1000, 69]), 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[4000:4500],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape, len(full_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1000, 64]), 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[4500:5000],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape, len(full_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([354, 76]), 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inps = tokenizer(df_test['in'].values.tolist()[5000:],\n",
    "    padding=True, truncation=True, return_tensors=\"tf\")\n",
    "outs = model.generate(input_ids=inps['input_ids'],\n",
    "    do_sample=True, attention_mask=inps['attention_mask'], max_length=512,\n",
    "    top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=preds_returned)\n",
    "full_outs.append(outs)\n",
    "outs.shape, len(full_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/cs-7643/lib/python3.7/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in</th>\n",
       "      <th>expected</th>\n",
       "      <th>sentence_inputs</th>\n",
       "      <th>to_model</th>\n",
       "      <th>encoding</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCCW's chief operating officer, Mike Butcher, ...</td>\n",
       "      <td>Current Chief Operating Officer Mike Butcher a...</td>\n",
       "      <td>[PCCW's, chief, operating, officer,, Mike, But...</td>\n",
       "      <td>paraphrase: PCCW's chief operating officer, Mi...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(2104, shape=(), dtype=int32), tf.T...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "      <td>[[Mike, Butcher,, PCCW, Chief, Operating, Offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The world's two largest automakers said their ...</td>\n",
       "      <td>Domestic sales at both GM and No. 2 Ford Motor...</td>\n",
       "      <td>[The, world's, two, largest, automakers, said,...</td>\n",
       "      <td>paraphrase: The world's two largest automakers...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(37, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "      <td>[[Expatriate, American, shopping, numbers, fel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the federal Centers for Disease C...</td>\n",
       "      <td>The Centers for Disease Control and Prevention...</td>\n",
       "      <td>[According, to, the, federal, Centers, for, Di...</td>\n",
       "      <td>paraphrase: According to the federal Centers f...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(2150, shape=(), dtype=int32), tf.T...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "      <td>[[In, 2002,, there, were, 19, reported, cases,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
       "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
       "      <td>[A, tropical, storm, rapidly, developed, in, t...</td>\n",
       "      <td>paraphrase: A tropical storm rapidly developed...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(71, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "      <td>[[A, tropical, storm, in, the, Gulf, of, Mexic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The company didn't detail the costs of the rep...</td>\n",
       "      <td>But company officials expect the costs of the ...</td>\n",
       "      <td>[The, company, didn't, detail, the, costs, of,...</td>\n",
       "      <td>paraphrase: The company didn't detail the cost...</td>\n",
       "      <td>[input_ids, attention_mask]</td>\n",
       "      <td>((tf.Tensor(37, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...</td>\n",
       "      <td>[[The, company, doesn't, detail, the, costs, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  in  \\\n",
       "0  PCCW's chief operating officer, Mike Butcher, ...   \n",
       "1  The world's two largest automakers said their ...   \n",
       "2  According to the federal Centers for Disease C...   \n",
       "3  A tropical storm rapidly developed in the Gulf...   \n",
       "4  The company didn't detail the costs of the rep...   \n",
       "\n",
       "                                            expected  \\\n",
       "0  Current Chief Operating Officer Mike Butcher a...   \n",
       "1  Domestic sales at both GM and No. 2 Ford Motor...   \n",
       "2  The Centers for Disease Control and Prevention...   \n",
       "3  A tropical storm rapidly developed in the Gulf...   \n",
       "4  But company officials expect the costs of the ...   \n",
       "\n",
       "                                     sentence_inputs  \\\n",
       "0  [PCCW's, chief, operating, officer,, Mike, But...   \n",
       "1  [The, world's, two, largest, automakers, said,...   \n",
       "2  [According, to, the, federal, Centers, for, Di...   \n",
       "3  [A, tropical, storm, rapidly, developed, in, t...   \n",
       "4  [The, company, didn't, detail, the, costs, of,...   \n",
       "\n",
       "                                            to_model  \\\n",
       "0  paraphrase: PCCW's chief operating officer, Mi...   \n",
       "1  paraphrase: The world's two largest automakers...   \n",
       "2  paraphrase: According to the federal Centers f...   \n",
       "3  paraphrase: A tropical storm rapidly developed...   \n",
       "4  paraphrase: The company didn't detail the cost...   \n",
       "\n",
       "                      encoding  \\\n",
       "0  [input_ids, attention_mask]   \n",
       "1  [input_ids, attention_mask]   \n",
       "2  [input_ids, attention_mask]   \n",
       "3  [input_ids, attention_mask]   \n",
       "4  [input_ids, attention_mask]   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  ((tf.Tensor(2104, shape=(), dtype=int32), tf.T...   \n",
       "1  ((tf.Tensor(37, shape=(), dtype=int32), tf.Ten...   \n",
       "2  ((tf.Tensor(2150, shape=(), dtype=int32), tf.T...   \n",
       "3  ((tf.Tensor(71, shape=(), dtype=int32), tf.Ten...   \n",
       "4  ((tf.Tensor(37, shape=(), dtype=int32), tf.Ten...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...   \n",
       "1  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...   \n",
       "2  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...   \n",
       "3  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...   \n",
       "4  ((tf.Tensor(1, shape=(), dtype=int32), tf.Tens...   \n",
       "\n",
       "                                                 out  \n",
       "0  [[Mike, Butcher,, PCCW, Chief, Operating, Offi...  \n",
       "1  [[Expatriate, American, shopping, numbers, fel...  \n",
       "2  [[In, 2002,, there, were, 19, reported, cases,...  \n",
       "3  [[A, tropical, storm, in, the, Gulf, of, Mexic...  \n",
       "4  [[The, company, doesn't, detail, the, costs, o...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putting everything back together\n",
    "longest_out = max([x.shape[1] for x in full_outs])\n",
    "np_outs = None\n",
    "for batch in full_outs:\n",
    "    padded = np.pad(batch.numpy(), ((0, 0), (0, longest_out-batch.shape[1])), 'constant')\n",
    "    if np_outs is None:\n",
    "        np_outs = padded\n",
    "    else:\n",
    "        np_outs = np.concatenate((np_outs, padded), axis=0)\n",
    "sentence_outputs = np.reshape(\n",
    "    [x.split() for x in tokenizer.batch_decode(np_outs, skip_special_tokens=True)],\n",
    "    (df_test.shape[0], -1))\n",
    "to_df = [list(x) for x in sentence_outputs] # allows us to put all generated sentences in 1 column in list form\n",
    "df_test['out'] = to_df\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.638831997077511 0.41971248401290545\n"
     ]
    }
   ],
   "source": [
    "sentence_inputs = [x.split() for x in df_test['in'].values.tolist()]\n",
    "sentence_expected = [x.split() for x in df_test['expected'].values.tolist()]\n",
    "sentence_outputs = df_test['out'].values.tolist()\n",
    "input_bleu = corpus_bleu(sentence_outputs, sentence_inputs)\n",
    "exp_bleu = corpus_bleu(sentence_outputs, sentence_expected)\n",
    "print(input_bleu, exp_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PCCW's chief operating officer, Mike Butcher, and Alex Arena, the chief financial officer, will report directly to Mr So.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('./data/combined_test_with_preds.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5fa2483a855b8d5bda0bee6a30ca1d19bc2df572f4161159be526481ad90098"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('cs-7643')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
