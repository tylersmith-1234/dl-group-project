{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inference1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49d64a3629074b7da0f73a60c9fd1b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca4ad23e9a5e4093bc91fbd00556659f",
              "IPY_MODEL_7d697e63deef40338b3d1f4d5ebe4b40",
              "IPY_MODEL_2fbff904dcac4c7d80ba6d8e62c3fdfe"
            ],
            "layout": "IPY_MODEL_18b8d6d7c67847d1a00a5d58ecd86004"
          }
        },
        "ca4ad23e9a5e4093bc91fbd00556659f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9f37424342f435bb3c2be242a640b0a",
            "placeholder": "​",
            "style": "IPY_MODEL_883d63c00ca84f8b8bbd139669c45bf7",
            "value": "Downloading: 100%"
          }
        },
        "7d697e63deef40338b3d1f4d5ebe4b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05568e8b96754dca97392996e4ebe1df",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c29db9a7bcfe4fe0bd739ab5ad9513dc",
            "value": 791656
          }
        },
        "2fbff904dcac4c7d80ba6d8e62c3fdfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_017ab3fa00bb4d89b86286042bb8d384",
            "placeholder": "​",
            "style": "IPY_MODEL_cb94cfacc6db493d94c37460c4f74bf0",
            "value": " 773k/773k [00:00&lt;00:00, 2.91MB/s]"
          }
        },
        "18b8d6d7c67847d1a00a5d58ecd86004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9f37424342f435bb3c2be242a640b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883d63c00ca84f8b8bbd139669c45bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05568e8b96754dca97392996e4ebe1df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c29db9a7bcfe4fe0bd739ab5ad9513dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "017ab3fa00bb4d89b86286042bb8d384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb94cfacc6db493d94c37460c4f74bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3d1a261b1ac403ab201fcf62338e96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3556b2e16b6f4cd7ad646bcec29e8fe9",
              "IPY_MODEL_ad47fcd29fcd4fe9a555bb8299a2044e",
              "IPY_MODEL_ec03ccf139a8461a968229589e6e675b"
            ],
            "layout": "IPY_MODEL_139d965add7a4aeeb7bfb89c0c35ccea"
          }
        },
        "3556b2e16b6f4cd7ad646bcec29e8fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ebcde13e2734c308379b1bb24a31839",
            "placeholder": "​",
            "style": "IPY_MODEL_3302d625cd0e4f1cae848663d91a63e8",
            "value": "Downloading: 100%"
          }
        },
        "ad47fcd29fcd4fe9a555bb8299a2044e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebc31cca2a9d41e4a880314a50e64202",
            "max": 1197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a770f4049cdb47849462ed1074a805d7",
            "value": 1197
          }
        },
        "ec03ccf139a8461a968229589e6e675b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcb1496abba245b1b454bd7c61b152fe",
            "placeholder": "​",
            "style": "IPY_MODEL_d873baebba2b4ec78a7bbff5c8e0c335",
            "value": " 1.17k/1.17k [00:00&lt;00:00, 2.69kB/s]"
          }
        },
        "139d965add7a4aeeb7bfb89c0c35ccea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ebcde13e2734c308379b1bb24a31839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3302d625cd0e4f1cae848663d91a63e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebc31cca2a9d41e4a880314a50e64202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a770f4049cdb47849462ed1074a805d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcb1496abba245b1b454bd7c61b152fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d873baebba2b4ec78a7bbff5c8e0c335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86023563ff1140f79d2b9de8a9c83d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_590fd2ab43de42788892caafc97f7151",
              "IPY_MODEL_1c14686cfc764d18ab1bac98009cfd30",
              "IPY_MODEL_85f4c137c5fc41eb9b8d7e6789d01a55"
            ],
            "layout": "IPY_MODEL_2b73a325e84d404c9bd9041f2b3c6438"
          }
        },
        "590fd2ab43de42788892caafc97f7151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b745d860ded4d3485594c7b1bbd6767",
            "placeholder": "​",
            "style": "IPY_MODEL_fea893c9121f492884a39b47e8bad681",
            "value": "Downloading: 100%"
          }
        },
        "1c14686cfc764d18ab1bac98009cfd30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b834d8ad945040bd8b49c6775b0a0600",
            "max": 242065649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef720717d5314222bbccf3e7ce28647b",
            "value": 242065649
          }
        },
        "85f4c137c5fc41eb9b8d7e6789d01a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a23099cb6f5446b84e1a5a63e2a8e9b",
            "placeholder": "​",
            "style": "IPY_MODEL_7c0918fe9b474c02ad6ecf9699c30c19",
            "value": " 231M/231M [00:08&lt;00:00, 26.4MB/s]"
          }
        },
        "2b73a325e84d404c9bd9041f2b3c6438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b745d860ded4d3485594c7b1bbd6767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea893c9121f492884a39b47e8bad681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b834d8ad945040bd8b49c6775b0a0600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef720717d5314222bbccf3e7ce28647b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a23099cb6f5446b84e1a5a63e2a8e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c0918fe9b474c02ad6ecf9699c30c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxsiwUdwmY4t"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: change path `/content/drive/MyDrive/`"
      ],
      "metadata": {
        "id": "oHQsHBfIcZNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ymi8MgSmbXB",
        "outputId": "df21667f-ecac-4d76-fdce-81dee6475a31"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            " \u001b[0m\u001b[01;34mcheckpoints_adapter_compacter\u001b[0m/      \u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
            " \u001b[01;34mcheckpoints_adapter_compacter_pp\u001b[0m/    \u001b[01;34mCOMBINED\u001b[0m/\n",
            " \u001b[01;34mcheckpoints_adapter_houlsby_inv\u001b[0m/     \u001b[01;34mcustom_adapters\u001b[0m/\n",
            " \u001b[01;34mcheckpoints_adapter_houlsby_inv2\u001b[0m/    CustomTrainerCallback.py\n",
            " \u001b[01;34mcheckpoints_adapter_mam\u001b[0m/             model_inference.py\n",
            " \u001b[01;34mcheckpoints_adapter_pfeiffer_inv\u001b[0m/    ParaphrasePipeline.py\n",
            " \u001b[01;34mcheckpoints_adapter_prefix_tuning\u001b[0m/   \u001b[01;34m__pycache__\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mMNVbvumY4u",
        "outputId": "87a8ad69-9894-4921-f8bb-a307f2f7cddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 32.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n",
            "Collecting adapter-transformers\n",
            "  Downloading adapter_transformers-3.0.0-py3-none-any.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->adapter-transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->adapter-transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->adapter-transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (1.15.0)\n",
            "Installing collected packages: adapter-transformers\n",
            "Successfully installed adapter-transformers-3.0.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.6 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 45.6 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 49.0 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.6.2-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.3.0)\n",
            "Collecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.2.0)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.8.1-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.11.0+cu113)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.8)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.44.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n",
            "Installing collected packages: pyDeprecate, torchmetrics, pytorch-lightning\n",
            "Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.6.2 torchmetrics-0.8.1\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install adapter-transformers\n",
        "!pip install datasets\n",
        "!pip install pytorch_lightning\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ch1wPNihmY4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0bb4f3-04df-406e-9b14-2d486ea1c912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 29 03:40:58 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-QiYH4pXmY4w"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eSTPeDczmY4w"
      },
      "outputs": [],
      "source": [
        "# import transformers\n",
        "# import datasets\n",
        "\n",
        "# from transformers import (\n",
        "#     # AdamW, \n",
        "#     T5Model, \n",
        "#     T5ForConditionalGeneration, \n",
        "#     T5AdapterModel, \n",
        "#     T5Tokenizer, \n",
        "#     get_linear_schedule_with_warmup,\n",
        "#     TrainingArguments, \n",
        "#     AdapterTrainer,\n",
        "#     Trainer\n",
        "# )\n",
        "\n",
        "# from dataprovider.DataProvider import DatasetProvider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzpyRkb9mY4y"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dxeb0j0ImY4y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hita6DuhmY4z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "49d64a3629074b7da0f73a60c9fd1b36",
            "ca4ad23e9a5e4093bc91fbd00556659f",
            "7d697e63deef40338b3d1f4d5ebe4b40",
            "2fbff904dcac4c7d80ba6d8e62c3fdfe",
            "18b8d6d7c67847d1a00a5d58ecd86004",
            "d9f37424342f435bb3c2be242a640b0a",
            "883d63c00ca84f8b8bbd139669c45bf7",
            "05568e8b96754dca97392996e4ebe1df",
            "c29db9a7bcfe4fe0bd739ab5ad9513dc",
            "017ab3fa00bb4d89b86286042bb8d384",
            "cb94cfacc6db493d94c37460c4f74bf0",
            "c3d1a261b1ac403ab201fcf62338e96f",
            "3556b2e16b6f4cd7ad646bcec29e8fe9",
            "ad47fcd29fcd4fe9a555bb8299a2044e",
            "ec03ccf139a8461a968229589e6e675b",
            "139d965add7a4aeeb7bfb89c0c35ccea",
            "8ebcde13e2734c308379b1bb24a31839",
            "3302d625cd0e4f1cae848663d91a63e8",
            "ebc31cca2a9d41e4a880314a50e64202",
            "a770f4049cdb47849462ed1074a805d7",
            "dcb1496abba245b1b454bd7c61b152fe",
            "d873baebba2b4ec78a7bbff5c8e0c335"
          ]
        },
        "outputId": "5a78eb52-e857-4bf2-f81d-8f40467d40b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49d64a3629074b7da0f73a60c9fd1b36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3d1a261b1ac403ab201fcf62338e96f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import T5Tokenizer\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(base_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "TG4FmGNmmY40",
        "outputId": "7ab80745-afbd-4b9d-e884-916d77279a0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     in  \\\n",
              "0     PCCW's chief operating officer, Mike Butcher, ...   \n",
              "1     The world's two largest automakers said their ...   \n",
              "2     According to the federal Centers for Disease C...   \n",
              "3     A tropical storm rapidly developed in the Gulf...   \n",
              "4     The company didn't detail the costs of the rep...   \n",
              "...                                                 ...   \n",
              "5172  Twice Sparrow sold the island twice to Thomas ...   \n",
              "5173  The name in Tupi means `` insensitive stone ''...   \n",
              "5174  The company has branches in Tokyo , based in t...   \n",
              "5175  The modern coat of arms of Bavaria was designe...   \n",
              "5176  It is located near Point Pleasant Borough , a ...   \n",
              "\n",
              "                                               expected  \n",
              "0     Current Chief Operating Officer Mike Butcher a...  \n",
              "1     Domestic sales at both GM and No. 2 Ford Motor...  \n",
              "2     The Centers for Disease Control and Prevention...  \n",
              "3     A tropical storm rapidly developed in the Gulf...  \n",
              "4     But company officials expect the costs of the ...  \n",
              "...                                                 ...  \n",
              "5172  Sparrow twice sold the island to Thomas Polloc...  \n",
              "5173  The name in Tupi means '' hard stone `` , '' i...  \n",
              "5174  The company has branches in Tokyo based in Sai...  \n",
              "5175  The modern coat of arms of Bavaria was designe...  \n",
              "5176  It is near Point Pleasant borough , a municipa...  \n",
              "\n",
              "[5177 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86d41d7a-f411-40c3-ac0b-80a7f67c74b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>in</th>\n",
              "      <th>expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PCCW's chief operating officer, Mike Butcher, ...</td>\n",
              "      <td>Current Chief Operating Officer Mike Butcher a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The world's two largest automakers said their ...</td>\n",
              "      <td>Domestic sales at both GM and No. 2 Ford Motor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>According to the federal Centers for Disease C...</td>\n",
              "      <td>The Centers for Disease Control and Prevention...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
              "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The company didn't detail the costs of the rep...</td>\n",
              "      <td>But company officials expect the costs of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5172</th>\n",
              "      <td>Twice Sparrow sold the island twice to Thomas ...</td>\n",
              "      <td>Sparrow twice sold the island to Thomas Polloc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5173</th>\n",
              "      <td>The name in Tupi means `` insensitive stone ''...</td>\n",
              "      <td>The name in Tupi means '' hard stone `` , '' i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5174</th>\n",
              "      <td>The company has branches in Tokyo , based in t...</td>\n",
              "      <td>The company has branches in Tokyo based in Sai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5175</th>\n",
              "      <td>The modern coat of arms of Bavaria was designe...</td>\n",
              "      <td>The modern coat of arms of Bavaria was designe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5176</th>\n",
              "      <td>It is located near Point Pleasant Borough , a ...</td>\n",
              "      <td>It is near Point Pleasant borough , a municipa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5177 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86d41d7a-f411-40c3-ac0b-80a7f67c74b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86d41d7a-f411-40c3-ac0b-80a7f67c74b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86d41d7a-f411-40c3-ac0b-80a7f67c74b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_test = pd.read_csv('COMBINED/test.tsv', sep = '\\t', names=['in', 'expected'])\n",
        "df_train = pd.read_csv('COMBINED/train.tsv', sep = '\\t', names=['in', 'expected'])\n",
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Saved Model"
      ],
      "metadata": {
        "id": "X16LuOayaScS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uymxFbJAmY4x"
      },
      "outputs": [],
      "source": [
        "base_path = \"t5-small\"\n",
        "adapter_path = \"paraphrase\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.adapters import T5AdapterModel"
      ],
      "metadata": {
        "id": "DCK3JIW4Z-dP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "bAf2YOscKjQZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: change the `saved_model_dir` to match the path to your saved model"
      ],
      "metadata": {
        "id": "XLg9Oj0YaZdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_dir = \"/content/drive/MyDrive/custom_adapters/houlsby-inv-sm\" \n",
        "\n",
        "model = T5AdapterModel.from_pretrained(base_path)\n",
        "model.load_adapter(f\"{saved_model_dir}\")\n",
        "model.set_active_adapters(adapter_path)\n",
        "print(model.active_adapters)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "86023563ff1140f79d2b9de8a9c83d96",
            "590fd2ab43de42788892caafc97f7151",
            "1c14686cfc764d18ab1bac98009cfd30",
            "85f4c137c5fc41eb9b8d7e6789d01a55",
            "2b73a325e84d404c9bd9041f2b3c6438",
            "7b745d860ded4d3485594c7b1bbd6767",
            "fea893c9121f492884a39b47e8bad681",
            "b834d8ad945040bd8b49c6775b0a0600",
            "ef720717d5314222bbccf3e7ce28647b",
            "3a23099cb6f5446b84e1a5a63e2a8e9b",
            "7c0918fe9b474c02ad6ecf9699c30c19"
          ]
        },
        "id": "EcH3zrS4KMiP",
        "outputId": "3b3c3e21-2c9b-4379-cb6a-348830bc0d24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86023563ff1140f79d2b9de8a9c83d96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at t5-small were not used when initializing T5AdapterModel: ['decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight']\n",
            "- This IS expected if you are initializing T5AdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5AdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of T5AdapterModel were not initialized from the model checkpoint at t5-small and are newly initialized: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stack[paraphrase]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5AdapterModel(\n",
              "  (shared_parameters): ModuleDict()\n",
              "  (transformer): T5Model(\n",
              "    (shared_parameters): ModuleDict()\n",
              "    (invertible_adapters): ModuleDict(\n",
              "      (paraphrase): NICECouplingBlock(\n",
              "        (F): Sequential(\n",
              "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (1): Activation_Function_Class(\n",
              "            (f): SiLUActivation()\n",
              "          )\n",
              "          (2): Linear(in_features=128, out_features=256, bias=True)\n",
              "        )\n",
              "        (G): Sequential(\n",
              "          (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "          (1): Activation_Function_Class(\n",
              "            (f): SiLUActivation()\n",
              "          )\n",
              "          (2): Linear(in_features=128, out_features=256, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (shared): Embedding(32128, 512)\n",
              "    (encoder): T5Stack(\n",
              "      (invertible_adapters): ModuleDict(\n",
              "        (paraphrase): NICECouplingBlock(\n",
              "          (F): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (1): Activation_Function_Class(\n",
              "              (f): SiLUActivation()\n",
              "            )\n",
              "            (2): Linear(in_features=128, out_features=256, bias=True)\n",
              "          )\n",
              "          (G): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (1): Activation_Function_Class(\n",
              "              (f): SiLUActivation()\n",
              "            )\n",
              "            (2): Linear(in_features=128, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (4): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (decoder): T5Stack(\n",
              "      (invertible_adapters): ModuleDict()\n",
              "      (embed_tokens): Embedding(32128, 512)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 8)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict()\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict()\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict()\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict()\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (4): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict()\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (1): T5LayerCrossAttention(\n",
              "              (EncDecAttention): T5Attention(\n",
              "                (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "                (prefix_tuning): PrefixTuningShim(\n",
              "                  (pool): PrefixTuningPool(\n",
              "                    (prefix_tunings): ModuleDict()\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict()\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "            (2): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseReluDense(\n",
              "                (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "                (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (adapters): ModuleDict(\n",
              "                (paraphrase): Adapter(\n",
              "                  (non_linearity): Activation_Function_Class(\n",
              "                    (f): SiLUActivation()\n",
              "                  )\n",
              "                  (adapter_down): Sequential(\n",
              "                    (0): Linear(in_features=512, out_features=32, bias=True)\n",
              "                    (1): Activation_Function_Class(\n",
              "                      (f): SiLUActivation()\n",
              "                    )\n",
              "                  )\n",
              "                  (adapter_up): Linear(in_features=32, out_features=512, bias=True)\n",
              "                )\n",
              "              )\n",
              "              (adapter_fusion_layer): ModuleDict()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (prefix_tuning): PrefixTuningPool(\n",
              "      (prefix_tunings): ModuleDict()\n",
              "    )\n",
              "  )\n",
              "  (heads): ModuleDict(\n",
              "    (paraphrase): Seq2SeqLMHead(\n",
              "      (0): Linear(in_features=512, out_features=32128, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have the `model_inference.py` file, you could import the inference function with:\n",
        "- `from model_inference import inference`"
      ],
      "metadata": {
        "id": "jbj712Kpa-8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_predictions(model, tokenizer, row:pd.Series, device=\"cpu\", num_return_sequences=5, verbose=True):\n",
        "    \"\"\"\n",
        "    Given a row of test dataframe, generate predictions\n",
        "    Args:\n",
        "        model (transformers.AutoAdapterModel)\n",
        "        tokenizer (transformers.AutoTokenizer or T5Tokenizer)\n",
        "        row (pd.Series): a row of a pd.DataFrame\n",
        "        device (str): device the model is on \"cpu\" or \"cuda\" \n",
        "        num_return_sequences (int): number of predictions to make\n",
        "        verbose (bool): whether to print outputs\n",
        "    Returns:\n",
        "        list of prediction strings\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose is True:\n",
        "        print('Input: ', row['in'])\n",
        "    \n",
        "    to_model = 'paraphrase: ' + row['in']\n",
        "\n",
        "    # sentence = 'paraphrase: We should go to the movies today because it is raining.'\n",
        "    encoding = tokenizer(row['in'], return_tensors=\"pt\")\n",
        "    \n",
        "    # Push tensors to device\n",
        "    for key, value in encoding.items():\n",
        "        encoding[key] = value.to(device)\n",
        "    \n",
        "    # Generate\n",
        "    input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "    out = model.generate(input_ids=input_ids, do_sample=True, attention_mask=attention_masks, max_length=512,\n",
        "                        top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=num_return_sequences)\n",
        "    \n",
        "    # Decode generated predictions\n",
        "    predictions = []\n",
        "    for p in out:\n",
        "        pred = tokenizer.decode(p, skip_special_tokens=True)\n",
        "        predictions.append(pred)\n",
        "        if verbose is True:\n",
        "            print('Prediction: ', pred)\n",
        "        \n",
        "    if verbose is True:\n",
        "        print('Expected: ', row['expected'], \"\\n\")\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def inference(model, tokenizer, df_test, num_examples=1, device=\"cpu\", verbose=True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate and print output for a few of the test dataset \n",
        "    Args:\n",
        "        model (transformers.AutoAdapterModel)\n",
        "        tokenizer (transformers.AutoTokenizer or T5Tokenizer)\n",
        "        df_test (pd.DataFrame)\n",
        "        num_examples (int): number of test sentences to generate paraphrase for\n",
        "        device (str): device the model is on \"cpu\" or \"cuda\"\n",
        "    Returns:\n",
        "        df_test_head_copy (pd.DataFrame): a copy of the first num_examples rows of the df_test\n",
        "            dataframe with the predictions appended as additional columns pred1, pred2, pred3, ...\n",
        "    \"\"\"\n",
        "\n",
        "    num_return_sequences = 5\n",
        "    \n",
        "    df_test_head_copy = df_test.head(num_examples).copy(deep=True)\n",
        "\n",
        "    predictions = df_test_head_copy.apply(lambda row: \n",
        "        generate_predictions(model, tokenizer, row, \n",
        "            device=device, num_return_sequences=num_return_sequences, \n",
        "            verbose=verbose\n",
        "        ), \n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    df_test_head_copy[[f\"pred{i}\" for i in range(1,num_return_sequences+1)]] = pd.DataFrame(np.vstack(predictions))\n",
        "\n",
        "    return df_test_head_copy\n",
        "\n"
      ],
      "metadata": {
        "id": "W1dPICwAK2vS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Predictions with `inference()`"
      ],
      "metadata": {
        "id": "1fuexZuQbNgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = inference(model, tokenizer, df_test, num_examples=10, device=device, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow-H4BB3LBGg",
        "outputId": "8c496cd9-ed88-4d63-b9e5-ebe55d1865d0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  PCCW's chief operating officer, Mike Butcher, and Alex Arena, the chief financial officer, will report directly to Mr So.\n",
            "Prediction:  The CCW Chief Operating Officer and Chairman of PCCW and the chief financial officer, Mike Butcher, chief operating officer of PCCW, and Alex Arena, chief financial officer, will report directly to Mr Socher.\n",
            "Prediction:  The chief operating officer of PCCW's chief operating officer, Mike Butcher, and Alex Arena, the chief financial officer, will be named Director with a video to Mr Socher and Alex Arena, the chief financial officer of PCCW's PCCW chief operating officer Mike Butcher, and Alex Arena in the op.\n",
            "Prediction:  The Chief Operating Officer and Chief Financial Officer of PCCW's chief operating officer Mike Butcher, and Alex Arena, the chief financial officer of PCCW, will have the option of reporting directly to Mr Socher.\n",
            "Prediction:  The chief operating officer for PCCW's chief operating officer, Mike Butcher, and Alex Arena (finance officer), the chief financial officer, will risk the PCCW's chief operating officer and financial officer.\n",
            "Prediction:  The Chief Operating Officer (Cespionage officer of PCCW HQ, Mike Butcher, and Alex Arena, the chief financial officer of PCCW, Mike Butcher, and Alex Arena, the chief operating officer (levels of PCCW head staff from PCCW to PCCW's chief operating officer, will report directly to Mr Socher.\n",
            "Expected:  Current Chief Operating Officer Mike Butcher and Group Chief Financial Officer Alex Arena will report to So. \n",
            "\n",
            "Input:  The world's two largest automakers said their U.S. sales declined more than predicted last month as a late summer sales frenzy caused more of an industry backlash than expected.\n",
            "Prediction:  The world's two largest automakers said U.S. sales declined more than forecast last month as a late summer sales frenzy caused more of a sales frenzy leading to an industry backlash than predicted last month. Europe's two major automakers said their U.S. sales declined more than first during this time, United States alone are the world's two largest automakers said their US sales had declined significantly since next May,\n",
            "Prediction:  It's the third largest automaker in the world to last month said its U.S. sales declined more than predicted last month, as it caused a late summer sales frenzy that caused greater global backlash than expected.\n",
            "Prediction:  The world's largest automaker said U.S. sales declined more than predicted last month owing to late summer sales frenzy.\n",
            "Prediction:  The world's two largest automakers say by late summer sales declines more than predicted by the season last month as late summer sales frenzy caused more of an industry backlash than expected as a late summer sales frenzy and late summer sales declines more than predicted last year's Carmakers told the world's two largest automakers said their carmakers said their U.S. sales last month have declined more than\n",
            "Prediction:  The world's two largest automakers said their U.S. sales declined more than predicted last month as a late summer sales frenzy did not impact a party since a late summer sales frenzy caused more of an industry backlash than expected.\n",
            "Expected:  Domestic sales at both GM and No. 2 Ford Motor Co. declined more than predicted as a late summer sales frenzy prompted a larger-than-expected industry backlash. \n",
            "\n",
            "Input:  According to the federal Centers for Disease Control and Prevention (news - web sites), there were 19 reported cases of measles in the United States in 2002.\n",
            "Prediction:  In 2002, 19 reported cases of measle of measles in the U.S. were reported in 19 cities.\n",
            "Prediction:  According to the Federal Centers for Disease Control and Prevention (news - web sites) there were 19 reported cases of rougeole in the United States in 2002.\n",
            "Prediction:  The federal Centers for Disease Control and Prevention (se - Web sites are the federal Centers for Disease Control and Prevention (BCDC) says 19 cases of measles in 2002 in the United States were reported in 2002 for measles in Kenya in and around. According to the Federal Centers for Disease Control and Prevention (news – 19 cases of Measles - The Central American Centers for the Federal Center, \"We are\n",
            "Prediction:  Selon the federal Centers for Disease Control and Prevention (News - Web Sites), the United States had 19 reported cases of malaria in 2002.\n",
            "Prediction:  According to the Federal Centers for Disease Control and Prevention (community - web sites) there were 19 reported cases of measles in the United States in 2002.\n",
            "Expected:  The Centers for Disease Control and Prevention said there were 19 reported cases of measles in the United States in 2002. \n",
            "\n",
            "Input:  A tropical storm rapidly developed in the Gulf of Mexico Sunday and was expected to hit somewhere along the Texas or Louisiana coasts by Monday night.\n",
            "Prediction:  The tropical storm had developed Sunday in the Gulf of Mexico and was expected to hit a band of Mexican officials that had been scheduled to reach a station of high blood just before Monday night.\n",
            "Prediction:  Sung by Texas or Louisiana by Monday night night was expected to strike by Monday night. An tropical storm rapidly developed in the Gulf of Mexico Sunday and was predicted to hit any part of the Texas or Louisiana border with a tropical storm Tuesday night.\n",
            "Prediction:  It was expected to hit somewhere along the Texas or Louisiana coast over Monday night - after a tropical storm hit a tropical storm is expected to hit on Monday night in the Gulf of Mexico.\n",
            "Prediction:  It has been reported that a tropical storm would reach throughout the Gulf of Mexico region later in the week and may hit some coastal miles to the Texas or Louisiana coasts of Texas and Louisiana coastal shores by Monday night. A tropical storm rapidly developed in the Gulf of Mexico Sunday and expected to hit May to hit Louisiana Coasts and Texas Friday night and Monday night, at least one year later.\n",
            "Prediction:  The Tropical storm rapidly developed in the Gulf of Mexico Sunday and was expected to hit somewhere along the Texas or Louisiana coasts Monday night by Monday evening.\n",
            "Expected:  A tropical storm rapidly developed in the Gulf of Mexico on Sunday and could have hurricane-force winds when it hits land somewhere along the Louisiana coast Monday night. \n",
            "\n",
            "Input:  The company didn't detail the costs of the replacement and repairs.\n",
            "Prediction:  The company didn't detail details the costs for the replacement and repairs of the replacement and repairs.\n",
            "Prediction:  The company disclosed the cost of the replacement and repairs and repairs, however, no details at all.\n",
            "Prediction:  The company did not detail the cost of the home-repair and repairs after the repairs and replacement of the replacement and repairs.\n",
            "Prediction:  The company wasn't detailed the possible costs for the replacement and repairs.\n",
            "Prediction:  The company had given no details about the cost of the replacement and repairs for the repairs and repairs.\n",
            "Expected:  But company officials expect the costs of the replacement work to run into the millions of dollars. \n",
            "\n",
            "Input:  The settling companies would also assign their possible claims against the underwriters to the investor plaintiffs, he added.\n",
            "Prediction:  The settlement companies also would assign their possible claims against the underwriters an investor defendants to the plaintiffs of an investor plaintiffs to the settling companies - he added.\n",
            "Prediction:  He added that however, their settlement companies would also assign pending claims against the underwriters to the investor plaintiffs and the settling companies.\n",
            "Prediction:  The settling companies would charge the settlement companies a favorable of the underwriting companies to charge the investor plaintiffs the investor plaintiffs later if the action occurred on the claimants. The companies that settled later would also assign their possible claims against the settling companies to all plaintiffs by distributing their claims against the Underwriters.\n",
            "Prediction:  The settling companies would also assign their possible claims against the underwriters to the investor plaintiffs, he said.\n",
            "Prediction:  The settling companies would also assign its possible claims against the underwriters underwriters to the investor plaintiffs, he said. The settling companies would also assign their possible claims against the underwriters to the investor plaintiffs.\n",
            "Expected:  Under the agreement, the settling companies will also assign their potential claims against the underwriters to the investors, he added. \n",
            "\n",
            "Input:  Air Commodore Quaife said the Hornets remained on three-minute alert throughout the operation.\n",
            "Prediction:  Air Commodore Quaife said the Hornets were on three minute alert throughout the operation while the Hornets remained on three minute alert for the area.\n",
            "Prediction:  He said the Hornets were on three minute alert throughout the operation, according to Air Commodore Quaife, Air Commodore Quaife said the Hornets remained immediately alerted every minute.\n",
            "Prediction:  Commodore Quaife stated that the Hornets kept on three minutes of sub- alert throughout the operation.\n",
            "Prediction:  The Hornets remain on 3-minute alert throughout the operation.\n",
            "Prediction:  The Hornets are with three seconds off to receive public alarm Monday through Wednesday.\n",
            "Expected:  Air Commodore John Quaife said the security operation was unprecedented. \n",
            "\n",
            "Input:  A Washington County man may have the countys first human case of West Nile virus, the health department said Friday.\n",
            "Prediction:  The health Department said the health department knew Friday that Washington County staff is told that Washington Countyans first people might have Washington County County man who would be recognized in Washington County may have the countys first human case commune, the health department said Friday.\n",
            "Prediction:  A Washington County man may have the countys first human case of west Nile virus in Washington County may have the first Western Neptill River virus in Washington County, said the health department Friday.\n",
            "Prediction:  The health department said a Washington County man may have the county first human case of West Nile virus of the world's highest virus is a Washington County man who may have the county's first virus on his computer, according to its sources in Washington, officials said.\n",
            "Prediction:  A Washington County resident may have the countys first human case of West Nil virus, according to the health department in Washington County. The hospital confirmed that the county owns first human case in Washington County involving the West Nil virus.\n",
            "Prediction:  A Washington County man who visited from a Washington County residents of Washington County may have the first U.S. Sheriff John John Penn said a government confirmed on Thursday, said his health officials in Washington County could have the first person in a man in a Washington County may have the first one may also have the countys first human case is on Washington County, Angaben from the health department says, a Washington County is\n",
            "Expected:  The countys first and only human case of West Nile this year was confirmed by health officials on Sept. 8. \n",
            "\n",
            "Input:  Moseley and a senior aide delivered their summary assessments to about 300 American and allied military officers on Thursday.\n",
            "Prediction:  Moseley and an a senior aide and d' 'Missieley and a senior aide s day, of Thursday, Moseley and a senior natur-\n",
            "Prediction:  Moseley & Joseph Moseley and a senior aide endorsed the OTTAWAL : Moseley and a senior Agricultural workers and also in Beth River who are meeting with strikingly and a cScient 73 on Thursday, the meeting will be held Thursday between Moseley and the \"Moseley and a senior aide wore on Thursday morning, the state of Washington,\n",
            "Prediction:  Moseley and a senior aide and a Senior aide on Thursday, on Thursday, near to 300 al Electronicin and an aide and a senior escorted a senior aide and a Moseley and an Assist reported Wednesday a news on June 29, Moseley and one of Bush and\n",
            "Prediction:  Moseley and a senior aide by several years of business with a senior aide delivered their summary assessments Thursday to about 300 US and allied military officers on Thursday, em-sourships were delivered Thursday on Monday, Moseley and a senior aides and a senior envilicin Division of the Commonwealth of California, the — on Wednesday morning —\n",
            "Prediction:  Moseley and one &\n",
            "Expected:  General Moseley and a senior aide presented their assessments at an internal briefing for American and allied military officers at Nellis Air Force Base in Nevada on Thursday. \n",
            "\n",
            "Input:  The broader Standard & Poor's 500 Index <.SPX> was 0.46 points lower, or 0.05 percent, at 997.02.\n",
            "Prediction:  A 9.97.02..SPX> gave Standard & Poors 500 Index 0.46 points lower, or 0.05 percent, at 997.02.\n",
            "Prediction:  The standard & Poor's 500 Index.SPX> was 0.46 points over (.SPX).SPX>, or 0.46 points lower, or 0.05 percent (0.06%) at 997,02 at the broader Standard & Poor's 500 Index had a.SPX > 0.46 points higher than the.SPX is 0.\n",
            "Prediction:  The overall Standard & Poor's 500 Index.SPX> was 0.46 points less, or 0.05 percent, at 997.02.\n",
            "Prediction:  The Greater Standard & Poor's 500 Index.SPX> was 0.46 points below the 10-point threshold of 90.02.\n",
            "Prediction:  The scale.SPX> Index was 0.46 points lower, or 0,05 percent, at 997.02.\n",
            "Expected:  The technology-laced Nasdaq Composite Index .IXIC was up 7.42 points, or 0.45 percent, at 1,653.44. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "o9wMQP8zMoID",
        "outputId": "6299bcdd-c021-40a0-d139-1afcdc66ba80"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  in  \\\n",
              "0  PCCW's chief operating officer, Mike Butcher, ...   \n",
              "1  The world's two largest automakers said their ...   \n",
              "2  According to the federal Centers for Disease C...   \n",
              "3  A tropical storm rapidly developed in the Gulf...   \n",
              "4  The company didn't detail the costs of the rep...   \n",
              "5  The settling companies would also assign their...   \n",
              "6  Air Commodore Quaife said the Hornets remained...   \n",
              "7  A Washington County man may have the countys f...   \n",
              "8  Moseley and a senior aide delivered their summ...   \n",
              "9  The broader Standard & Poor's 500 Index <.SPX>...   \n",
              "\n",
              "                                            expected  \\\n",
              "0  Current Chief Operating Officer Mike Butcher a...   \n",
              "1  Domestic sales at both GM and No. 2 Ford Motor...   \n",
              "2  The Centers for Disease Control and Prevention...   \n",
              "3  A tropical storm rapidly developed in the Gulf...   \n",
              "4  But company officials expect the costs of the ...   \n",
              "5  Under the agreement, the settling companies wi...   \n",
              "6  Air Commodore John Quaife said the security op...   \n",
              "7  The countys first and only human case of West ...   \n",
              "8  General Moseley and a senior aide presented th...   \n",
              "9  The technology-laced Nasdaq Composite Index .I...   \n",
              "\n",
              "                                               pred1  \\\n",
              "0  The CCW Chief Operating Officer and Chairman o...   \n",
              "1  The world's two largest automakers said U.S. s...   \n",
              "2  In 2002, 19 reported cases of measle of measle...   \n",
              "3  The tropical storm had developed Sunday in the...   \n",
              "4  The company didn't detail details the costs fo...   \n",
              "5  The settlement companies also would assign the...   \n",
              "6  Air Commodore Quaife said the Hornets were on ...   \n",
              "7  The health Department said the health departme...   \n",
              "8  Moseley and an a senior aide and d' 'Missieley...   \n",
              "9  A 9.97.02..SPX> gave Standard & Poors 500 Inde...   \n",
              "\n",
              "                                               pred2  \\\n",
              "0  The chief operating officer of PCCW's chief op...   \n",
              "1  It's the third largest automaker in the world ...   \n",
              "2  According to the Federal Centers for Disease C...   \n",
              "3  Sung by Texas or Louisiana by Monday night nig...   \n",
              "4  The company disclosed the cost of the replacem...   \n",
              "5  He added that however, their settlement compan...   \n",
              "6  He said the Hornets were on three minute alert...   \n",
              "7  A Washington County man may have the countys f...   \n",
              "8  Moseley & Joseph Moseley and a senior aide end...   \n",
              "9  The standard & Poor's 500 Index.SPX> was 0.46 ...   \n",
              "\n",
              "                                               pred3  \\\n",
              "0  The Chief Operating Officer and Chief Financia...   \n",
              "1  The world's largest automaker said U.S. sales ...   \n",
              "2  The federal Centers for Disease Control and Pr...   \n",
              "3  It was expected to hit somewhere along the Tex...   \n",
              "4  The company did not detail the cost of the hom...   \n",
              "5  The settling companies would charge the settle...   \n",
              "6  Commodore Quaife stated that the Hornets kept ...   \n",
              "7  The health department said a Washington County...   \n",
              "8  Moseley and a senior aide and a Senior aide on...   \n",
              "9  The overall Standard & Poor's 500 Index.SPX> w...   \n",
              "\n",
              "                                               pred4  \\\n",
              "0  The chief operating officer for PCCW's chief o...   \n",
              "1  The world's two largest automakers say by late...   \n",
              "2  Selon the federal Centers for Disease Control ...   \n",
              "3  It has been reported that a tropical storm wou...   \n",
              "4  The company wasn't detailed the possible costs...   \n",
              "5  The settling companies would also assign their...   \n",
              "6  The Hornets remain on 3-minute alert throughou...   \n",
              "7  A Washington County resident may have the coun...   \n",
              "8  Moseley and a senior aide by several years of ...   \n",
              "9  The Greater Standard & Poor's 500 Index.SPX> w...   \n",
              "\n",
              "                                               pred5  \n",
              "0  The Chief Operating Officer (Cespionage office...  \n",
              "1  The world's two largest automakers said their ...  \n",
              "2  According to the Federal Centers for Disease C...  \n",
              "3  The Tropical storm rapidly developed in the Gu...  \n",
              "4  The company had given no details about the cos...  \n",
              "5  The settling companies would also assign its p...  \n",
              "6  The Hornets are with three seconds off to rece...  \n",
              "7  A Washington County man who visited from a Was...  \n",
              "8                                  Moseley and one &  \n",
              "9  The scale.SPX> Index was 0.46 points lower, or...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22718ba7-6418-49c7-b5cd-d1f4bb17383c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>in</th>\n",
              "      <th>expected</th>\n",
              "      <th>pred1</th>\n",
              "      <th>pred2</th>\n",
              "      <th>pred3</th>\n",
              "      <th>pred4</th>\n",
              "      <th>pred5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PCCW's chief operating officer, Mike Butcher, ...</td>\n",
              "      <td>Current Chief Operating Officer Mike Butcher a...</td>\n",
              "      <td>The CCW Chief Operating Officer and Chairman o...</td>\n",
              "      <td>The chief operating officer of PCCW's chief op...</td>\n",
              "      <td>The Chief Operating Officer and Chief Financia...</td>\n",
              "      <td>The chief operating officer for PCCW's chief o...</td>\n",
              "      <td>The Chief Operating Officer (Cespionage office...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The world's two largest automakers said their ...</td>\n",
              "      <td>Domestic sales at both GM and No. 2 Ford Motor...</td>\n",
              "      <td>The world's two largest automakers said U.S. s...</td>\n",
              "      <td>It's the third largest automaker in the world ...</td>\n",
              "      <td>The world's largest automaker said U.S. sales ...</td>\n",
              "      <td>The world's two largest automakers say by late...</td>\n",
              "      <td>The world's two largest automakers said their ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>According to the federal Centers for Disease C...</td>\n",
              "      <td>The Centers for Disease Control and Prevention...</td>\n",
              "      <td>In 2002, 19 reported cases of measle of measle...</td>\n",
              "      <td>According to the Federal Centers for Disease C...</td>\n",
              "      <td>The federal Centers for Disease Control and Pr...</td>\n",
              "      <td>Selon the federal Centers for Disease Control ...</td>\n",
              "      <td>According to the Federal Centers for Disease C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
              "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
              "      <td>The tropical storm had developed Sunday in the...</td>\n",
              "      <td>Sung by Texas or Louisiana by Monday night nig...</td>\n",
              "      <td>It was expected to hit somewhere along the Tex...</td>\n",
              "      <td>It has been reported that a tropical storm wou...</td>\n",
              "      <td>The Tropical storm rapidly developed in the Gu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The company didn't detail the costs of the rep...</td>\n",
              "      <td>But company officials expect the costs of the ...</td>\n",
              "      <td>The company didn't detail details the costs fo...</td>\n",
              "      <td>The company disclosed the cost of the replacem...</td>\n",
              "      <td>The company did not detail the cost of the hom...</td>\n",
              "      <td>The company wasn't detailed the possible costs...</td>\n",
              "      <td>The company had given no details about the cos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The settling companies would also assign their...</td>\n",
              "      <td>Under the agreement, the settling companies wi...</td>\n",
              "      <td>The settlement companies also would assign the...</td>\n",
              "      <td>He added that however, their settlement compan...</td>\n",
              "      <td>The settling companies would charge the settle...</td>\n",
              "      <td>The settling companies would also assign their...</td>\n",
              "      <td>The settling companies would also assign its p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Air Commodore Quaife said the Hornets remained...</td>\n",
              "      <td>Air Commodore John Quaife said the security op...</td>\n",
              "      <td>Air Commodore Quaife said the Hornets were on ...</td>\n",
              "      <td>He said the Hornets were on three minute alert...</td>\n",
              "      <td>Commodore Quaife stated that the Hornets kept ...</td>\n",
              "      <td>The Hornets remain on 3-minute alert throughou...</td>\n",
              "      <td>The Hornets are with three seconds off to rece...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A Washington County man may have the countys f...</td>\n",
              "      <td>The countys first and only human case of West ...</td>\n",
              "      <td>The health Department said the health departme...</td>\n",
              "      <td>A Washington County man may have the countys f...</td>\n",
              "      <td>The health department said a Washington County...</td>\n",
              "      <td>A Washington County resident may have the coun...</td>\n",
              "      <td>A Washington County man who visited from a Was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Moseley and a senior aide delivered their summ...</td>\n",
              "      <td>General Moseley and a senior aide presented th...</td>\n",
              "      <td>Moseley and an a senior aide and d' 'Missieley...</td>\n",
              "      <td>Moseley &amp; Joseph Moseley and a senior aide end...</td>\n",
              "      <td>Moseley and a senior aide and a Senior aide on...</td>\n",
              "      <td>Moseley and a senior aide by several years of ...</td>\n",
              "      <td>Moseley and one &amp;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The broader Standard &amp; Poor's 500 Index &lt;.SPX&gt;...</td>\n",
              "      <td>The technology-laced Nasdaq Composite Index .I...</td>\n",
              "      <td>A 9.97.02..SPX&gt; gave Standard &amp; Poors 500 Inde...</td>\n",
              "      <td>The standard &amp; Poor's 500 Index.SPX&gt; was 0.46 ...</td>\n",
              "      <td>The overall Standard &amp; Poor's 500 Index.SPX&gt; w...</td>\n",
              "      <td>The Greater Standard &amp; Poor's 500 Index.SPX&gt; w...</td>\n",
              "      <td>The scale.SPX&gt; Index was 0.46 points lower, or...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22718ba7-6418-49c7-b5cd-d1f4bb17383c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22718ba7-6418-49c7-b5cd-d1f4bb17383c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22718ba7-6418-49c7-b5cd-d1f4bb17383c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Predictions with a Custom Pipeline"
      ],
      "metadata": {
        "id": "gxm1o4vdbXTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have the `ParaphrasePipeline.py` file, you could import this call as:\n",
        "- `from ParaphrasePipeline import ParaphrasePipeline`"
      ],
      "metadata": {
        "id": "CTW8Ig_Gbd7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Pipeline\n",
        "\n",
        "class ParaphrasePipeline(Pipeline):\n",
        "    def _sanitize_parameters(self, **pipeline_parameters):\n",
        "\n",
        "        print(\"pipeline parameters: \")\n",
        "        print(pipeline_parameters)\n",
        "        return dict(), dict(), dict()\n",
        "\n",
        "    def preprocess(self, input_, **preprocess_parameters):\n",
        "        \"\"\"Tokenize and convert input into torch encodings\"\"\"\n",
        "        print(\"preprocess:\")\n",
        "\n",
        "        device = self.device\n",
        "\n",
        "        if isinstance(input_, str):\n",
        "            encoding = self.tokenizer(f\"paraphrase: {input_}\", return_tensors=\"pt\")\n",
        "        \n",
        "            # Push tensors to device\n",
        "            for key, value in encoding.items():\n",
        "                encoding[key] = value.to(device)\n",
        "            \n",
        "            input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "            return {\"input_ids\": input_ids, \"attention_masks\": attention_masks}\n",
        "        \n",
        "        else:\n",
        "            raise Exception(f\"Unhandled input type: {type(input_)}\")\n",
        "\n",
        "    def _forward(self, input_tensors, **forward_parameters):\n",
        "        \"\"\"Generate text\"\"\"\n",
        "\n",
        "        print(\"_forward:\")\n",
        "        print(input_tensors)\n",
        "        num_return_sequences = 5\n",
        "        input_ids, attention_masks = input_tensors[\"input_ids\"], input_tensors[\"attention_masks\"]\n",
        "        out = self.model.generate(input_ids=input_ids, do_sample=True, attention_mask=attention_masks, max_length=512,\n",
        "                        top_k=250, top_p=0.99, early_stopping=True, num_return_sequences=num_return_sequences)\n",
        "        return out\n",
        "\n",
        "    def postprocess(self, model_outputs, **postprocess_parameters):\n",
        "        \"\"\"Decode model generated text\"\"\"\n",
        "\n",
        "        print(\"postprocess\")\n",
        "        print(model_outputs)\n",
        "        verbose=True\n",
        "        out = model_outputs\n",
        "        predictions = []\n",
        "        for p in out:\n",
        "            pred = self.tokenizer.decode(p, skip_special_tokens=True)\n",
        "            predictions.append(pred)\n",
        "            if verbose is True:\n",
        "                print('Prediction: ', pred)\n",
        "        \n",
        "        return predictions\n",
        "        # if verbose is True:\n",
        "        #     print('Expected: ', row['expected'], \"\\n\")"
      ],
      "metadata": {
        "id": "wt-r9n8DNOuj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize pipeline\n",
        "pipe = ParaphrasePipeline(\n",
        "    task=\"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=torch.cuda.current_device()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqVqOKqXUYcy",
        "outputId": "97fedff9-46e9-40f0-ff3f-fc7654d3b9b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline parameters: \n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "pipe(\"The settling companies would also assign their possible claims against the underwriters to the investor plaintiffs, he added.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWjGCaGVUhvr",
        "outputId": "0b0d2c48-96f3-496c-97d2-5d3ec2936355"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline parameters: \n",
            "{}\n",
            "preprocess:\n",
            "_forward:\n",
            "{'input_ids': tensor([[ 3856, 27111,    10,    37,     3, 19691,   688,   133,    92, 12317,\n",
            "            70,   487,  3213,   581,     8,   365, 12756,     7,    12,     8,\n",
            "         12024, 16877,     7,     6,     3,    88,   974,     5,     1]],\n",
            "       device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "postprocess\n",
            "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,    37,     3, 19691,\n",
            "           688,   133,    92, 12317,    70,   487,  3213,   581,     8,   365,\n",
            "         12756,     7,    12,  4367, 16877,     7,   113, 12967,    70,  8201,\n",
            "             3,     5,  1853,     3, 19691,   688,   133,    92, 12317,    70,\n",
            "          3213,   581,   273,   365, 12756,     7, 13741,    15,  3213,    13,\n",
            "             8, 16877,     7,    12,     8, 12024, 16877,     7,     6,     3,\n",
            "            88,   974,     5,     1,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0],\n",
            "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            37,  8955,   688,   133,    92, 12317,  1055,  3213,   581,     8,\n",
            "           365, 12756,     7,    70,     3, 19691,   688,    12,     8,  4367,\n",
            "         16877,     7,     3,    99,     8, 16877,     7,  5132,  3213,   581,\n",
            "             8,  2137,   277,    11,   119,  4367,   590,     8,   194,     6,\n",
            "             3,    88,   974,     5,     1,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0],\n",
            "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,   100,   133,   993,     8,   866,\n",
            "            13,   387,    45,     8,     3, 19691,   688,    16,     8,   688,\n",
            "            21,     8,  7025,   133,    92, 12317,    70,   487,  3213,   581,\n",
            "             8,   365, 12756,     7,    70,  3213,   581,     8,   365, 12756,\n",
            "             7,     8, 12024, 16877,     7,     6,   974,     3,     9,  1798,\n",
            "          2325, 14481,     5,    37,     3, 19691,   688,   133,    92, 12317,\n",
            "            70,   487,  3213,   581,     8,   365, 12756,     7,    12, 12024,\n",
            "         16877,     7,     6,    20,  4788,  1222,   133,    92,    43,  6059,\n",
            "            13,     8,  2713,    13,     8,     3, 19691,   688,    13,     8,\n",
            "             3,    31,    31,     1],\n",
            "        [    0,    37,     3, 19691,   688,   133,    92, 12317,    70,   487,\n",
            "          3213,   581,     8,   365, 12756,     7,    12,     8, 16877,     7,\n",
            "            13,     8, 12024,     6,     3,     9,  1798,  1798, 18179,  3069,\n",
            "          7930,   243,     5,     1,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0],\n",
            "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,    37,     3, 19691,   688,   133,    92,  5334,  7599,\n",
            "           581,     8,   365, 12756,     7,    11,  7000, 14733,     3,     9,\n",
            "          1253,    12,  1988,   581,     8,   365, 12756,     7,    12,   165,\n",
            "          4367, 16877,     7,     6,     3,    88,   974,     5,     1,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0]])\n",
            "Prediction:  The settling companies would also assign their possible claims against the underwriters to investors plaintiffs who rejected their contracts. THE settling companies would also assign their claims against those underwriters eventuale claims of the plaintiffs to the investor plaintiffs, he added.\n",
            "Prediction:  The settle companies would also assign potential claims against the underwriters their settling companies to the investors plaintiffs if the plaintiffs filed claims against the bankers and other investors along the way, he added.\n",
            "Prediction:  This would increase the amount of water from the settling companies in the companies for the settlement would also assign their possible claims against the underwriters their claims against the underwriters the investor plaintiffs, added a former mastermind. The settling companies would also assign their possible claims against the underwriters to investor plaintiffs, depleting would also have permission of the owners of the settling companies of the ''\n",
            "Prediction:  The settling companies would also assign their possible claims against the underwriters to the plaintiffs of the investor, a former former hedge fund boss said.\n",
            "Prediction:  The settling companies would also grant quotes against the underwriters and asset holders a chance to claim against the underwriters to its investors plaintiffs, he added.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The settling companies would also assign their possible claims against the underwriters to investors plaintiffs who rejected their contracts. THE settling companies would also assign their claims against those underwriters eventuale claims of the plaintiffs to the investor plaintiffs, he added.',\n",
              " 'The settle companies would also assign potential claims against the underwriters their settling companies to the investors plaintiffs if the plaintiffs filed claims against the bankers and other investors along the way, he added.',\n",
              " \"This would increase the amount of water from the settling companies in the companies for the settlement would also assign their possible claims against the underwriters their claims against the underwriters the investor plaintiffs, added a former mastermind. The settling companies would also assign their possible claims against the underwriters to investor plaintiffs, depleting would also have permission of the owners of the settling companies of the ''\",\n",
              " 'The settling companies would also assign their possible claims against the underwriters to the plaintiffs of the investor, a former former hedge fund boss said.',\n",
              " 'The settling companies would also grant quotes against the underwriters and asset holders a chance to claim against the underwriters to its investors plaintiffs, he added.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# It doesn't always work though:\n",
        "pipe(\"Help I've fallen and I can't get up!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp66gjDUb4xL",
        "outputId": "b1e677e6-6475-48e8-a33e-62003c22dec9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline parameters: \n",
            "{}\n",
            "preprocess:\n",
            "_forward:\n",
            "{'input_ids': tensor([[ 3856, 27111,    10,  5090,    27,    31,   162,  9717,    11,    27,\n",
            "            54,    31,    17,   129,    95,    55,     1]], device='cuda:0'), 'attention_masks': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "postprocess\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "Prediction:  \n",
            "Prediction:  \n",
            "Prediction:  \n",
            "Prediction:  \n",
            "Prediction:  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '', '', '', '']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S2Lqs1jab_5X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}